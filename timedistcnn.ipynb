{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = torch.rand(3,128,128)\n",
    "im2 = torch.rand(3,128,128)\n",
    "im3 = torch.rand(3,128,128)\n",
    "im4 = torch.rand(3,128,128)\n",
    "im5 = torch.rand(3,128,128)\n",
    "out = torch.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3, 128, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_w = torch.stack((im1,im2,im3,im4,im5),0)\n",
    "im_w = torch.unsqueeze(im_w,0)\n",
    "im_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timedistributed cnn network\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_f, out_f, *args, **kwargs):        \n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "            nn.BatchNorm2d(out_f),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, in_c, in_shape = 128 ,channels = [16, 32, 64]):        \n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.channels = [in_c] + channels\n",
    "        conv_blocks = [ConvBlock(in_f, out_f, kernel_size=3,stride = 2 , padding=1) \n",
    "                       for in_f, out_f in zip(self.channels, self.channels[1:])]\n",
    "        self.cnnmodule = nn.Sequential(*conv_blocks)\n",
    "        in_n = int(self.channels[-1]*(in_shape//(2**len(channels)))*(in_shape//(2**len(channels))))\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_n, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnnmodule(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, layer, time_steps, *args):        \n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.layers = nn.ModuleList([layer(*args) for i in range(time_steps)])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size, time_steps, C, H, W = x.size()\n",
    "        output = torch.tensor([])\n",
    "        for i in range(time_steps):\n",
    "          output_t = self.layers[i](x[:, i, :, :, :])\n",
    "          output_t  = output_t.unsqueeze(1)\n",
    "          output = torch.cat((output, output_t ), 1)\n",
    "        return output\n",
    "\n",
    "class LSTMModule(torch.nn.Module):\n",
    "    def __init__(self,n_features, n_hidden, n_layers, seq_len, n_out, bidirectional = True):\n",
    "        super(LSTMModule, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden # number of hidden states\n",
    "        self.n_layers = n_layers # number of LSTM layers (stacked)\n",
    "    \n",
    "        self.l_lstm = nn.LSTM(input_size = self.n_features, \n",
    "                                 hidden_size = self.n_hidden,\n",
    "                                 num_layers = self.n_layers, \n",
    "                                 batch_first = True,\n",
    "                                 bidirectional = bidirectional,\n",
    "                                 dropout = 0.2)\n",
    "        # according to pytorch docs LSTM output is \n",
    "        # (batch_size,seq_len, num_directions * hidden_size)\n",
    "        l = 2 if bidirectional else 1\n",
    "        self.decoder_network = nn.Sequential(\n",
    "            nn.Linear(self.n_hidden*seq_len*l, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_out)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, data, device = 'cpu'):        \n",
    "        batch_size, seq_len, _ = data.size()\n",
    "        hidden_state0 = torch.zeros(self.n_layers*2,batch_size,self.n_hidden).to(device)\n",
    "        cell_state0 = torch.zeros(self.n_layers*2,batch_size,self.n_hidden).to(device)\n",
    "\n",
    "        lstm_out, (hidden,cell) = self.l_lstm(data.float(),(hidden_state0,cell_state0))\n",
    "             \n",
    "        out = lstm_out.contiguous().view(batch_size,-1)\n",
    "        out = self.decoder_network(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNLSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNLSTMNet, self).__init__()\n",
    "        self.ts_cnn = TimeDistributed(CNNEncoder, ts, 3)\n",
    "        self.lstm_decoder = LSTMModule(1024, 128, 2, ts, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ts_cnn(x)\n",
    "        x = self.lstm_decoder(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmodel = CNNLSTMNet()\n",
    "o = nmodel(im_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180297730"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(nmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 5\n",
    "model = TimeDistributed(CNNEncoder, ts, 3)\n",
    "model1 = LSTMModule(1024, 128, 2, ts, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(im_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1024])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model1(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0596, -0.0491]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dc034823c925ab72675d722f7a4a6e69cee72befff823788c49c0ef66a71113"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
