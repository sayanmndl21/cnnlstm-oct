{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch;\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models \n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "#from model import VAE\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "from dataloader_pw import *\n",
    "from cnn_model_1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(iteration):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    #### dataset\n",
    "    #only on validation set\n",
    "    csv_path = 'pairwise_lstm.csv'\n",
    "    img_path = '/home/vip/sayan-mandal/datasets/obj_criteria/good_reduced/'\n",
    "\n",
    "    CDL = PWDataLoader(csv_path, img_path, transform = transforms.Compose([transforms.Resize(64),transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "\n",
    "    #random sampler\n",
    "    batch_size = 64\n",
    "    validation_split = .2\n",
    "    test_split = .2\n",
    "    train_split = 1-validation_split-test_split\n",
    "    shuffle_dataset = True\n",
    "\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(CDL)\n",
    "    indices = list(range(dataset_size))\n",
    "    split_train = int(np.floor(train_split * dataset_size))\n",
    "    split_valid = int(np.floor((train_split+validation_split) * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices, test_indices =  indices[:split_train],indices[split_train:split_valid],indices[split_valid:]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(CDL, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(CDL, batch_size=batch_size, sampler=valid_sampler)\n",
    "    test_loader = torch.utils.data.DataLoader(CDL, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "    ##### Model\n",
    "    torch.cuda.empty_cache()\n",
    "    tl = iter(train_loader)\n",
    "    dat,_,_ = next(tl)\n",
    "    bs, ts, C, H, W = dat.shape\n",
    "    n_out = 1\n",
    "\n",
    "    model = CNNLSTMNet(channels = C, ts = ts, n_out = n_out, device = device).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)  #,momentum=0.9, nesterov=True)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100], gamma= 0.1)\n",
    "    criterion = nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "    ##### trainingloop\n",
    "    epochs = 150\n",
    "    best_loss = float('inf')\n",
    "    ep, trainloss, validloss, testloss = [],[],[],[]\n",
    "    testep, totloss = [],[]\n",
    "    besttrloss, bestvalloss, besttsloss = 0,0,0\n",
    "    for epoch in range(1,epochs+1):\n",
    "        model.train()\n",
    "        #loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
    "        trloss = 0\n",
    "        for batch_idx, (data, targets, _) in loop:\n",
    "            optimizer.zero_grad() \n",
    "            data = Variable(data).to(device)\n",
    "            targets = Variable(targets.to(torch.float).view(targets.shape[0],-1)).to(device)\n",
    "\n",
    "            #forward pass\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "            trloss += loss.item()\n",
    "            #backward pass   \n",
    "            loss.backward()\n",
    "\n",
    "            #gradient descent\n",
    "            optimizer.step()\n",
    "            #loop.set_description(f\"Epoch [{epoch}/{epochs}]\")\n",
    "            #loop.set_postfix(batch_loss = loss.item(), running_loss = trloss )\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        valloss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, targets, _ in valid_loader:\n",
    "                data = Variable(data).to(device)\n",
    "                targets = Variable(targets.to(torch.float).view(targets.shape[0],-1)).to(device)\n",
    "\n",
    "                \n",
    "                scores = model(data)\n",
    "                loss = criterion(scores, targets)\n",
    "\n",
    "                valloss += loss.item()\n",
    "\n",
    "        if valloss < best_loss:\n",
    "            tsloss = 0\n",
    "            with torch.no_grad():\n",
    "                for data, targets, _ in test_loader:\n",
    "                    data = Variable(data).to(device)\n",
    "                    targets = Variable(targets.to(torch.float).view(targets.shape[0],-1)).to(device)\n",
    "\n",
    "                    \n",
    "                    scores = model(data)\n",
    "                    loss = criterion(scores, targets)\n",
    "\n",
    "                    tsloss += loss.item()\n",
    "                testloss += [tsloss]\n",
    "                testep += [epoch]\n",
    "            #to_print = \"Train Loss: {:.4f} | Valid Loss: {:.4f} ===========> {:.4f} | Test Loss: {:.4f} | Saving model...\".format(trloss, best_loss, valloss, tsloss)\n",
    "            best_loss = valloss\n",
    "            bestvalloss = valloss\n",
    "            besttrloss = trloss\n",
    "            besttsloss = tsloss\n",
    "            best_e = epoch\n",
    "            torch.save(model.state_dict(),'pw_statedict.pt')\n",
    "            #best_model = copy.deepcopy(model)\n",
    "        \n",
    "        #print(to_print)\n",
    "        ep+=[epoch]\n",
    "        trainloss += [trloss]\n",
    "        validloss += [valloss]\n",
    "        totloss += [trloss + valloss]\n",
    "\n",
    "    #### testing\n",
    "    tsloss = 0\n",
    "    model.load_state_dict(torch.load('pw_statedict.pt'))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets, _) in enumerate(test_loader):\n",
    "            data = Variable(data).to(device)\n",
    "            targets = Variable(targets.view(targets.shape[0],-1)).to(device)\n",
    "\n",
    "            \n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            if batch_idx == 0:\n",
    "                true_scores = targets.cpu().numpy()\n",
    "                pred_scores = scores.cpu().numpy()\n",
    "            else:\n",
    "                true_scores = np.append(true_scores, targets.cpu().numpy(), axis = 0)\n",
    "                pred_scores = np.append(pred_scores, scores.cpu().numpy(), axis = 0)\n",
    "\n",
    "\n",
    "            tsloss += loss.item()\n",
    "\n",
    "    dfx = pd.DataFrame.from_dict({'Slope ($\\mu$m/y)': true_scores.ravel().tolist(), 'Sample':'true scores'})\n",
    "    dfy = pd.DataFrame.from_dict({'Slope ($\\mu$m/y)': pred_scores.ravel().tolist(), 'Sample':'predicted scores'})\n",
    "    df = pd.concat(axis=0, ignore_index=True, objs=[dfx,dfy])\n",
    "    df.to_csv('predscores'+int(iteration)+'.csv', index=False)\n",
    "\n",
    "    ndf = pd.DataFrame({'ep': ep,\n",
    "    'train': trainloss,\n",
    "    'valid': validloss,'total':totloss})\n",
    "    ndf.to_csv('losses'+int(iteration)+'.csv', index=False)\n",
    "\n",
    "    ndf = pd.DataFrame({'ep': testep, 'test':testloss})\n",
    "    ndf.to_csv('testl'+int(iteration)+'.csv', index=False)\n",
    "    return besttrloss, bestvalloss, besttsloss, best_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrl, bvl, btsl, bep = [],[],[],[]\n",
    "for iteration in range(30):\n",
    "    besttrloss, bestvalloss, besttsloss, best_e = main(iteration)\n",
    "    btrl += [besttrloss]\n",
    "    bvl += [bestvalloss]\n",
    "    btsl += [besttsloss]\n",
    "    bep += [best_e]\n",
    "\n",
    "\n",
    "ndf = pd.DataFrame({'ep': bep,\n",
    "    'train': btrl,\n",
    "    'valid': bvl,\n",
    "    'test': btsl})\n",
    "ndf.to_csv('bestloss.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dc034823c925ab72675d722f7a4a6e69cee72befff823788c49c0ef66a71113"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
